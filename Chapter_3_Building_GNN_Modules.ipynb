{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfwTx6tr3KVyPBr1Tj43Ph",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zmgy107/DGL-Learning-Notes/blob/main/Chapter_3_Building_GNN_Modules.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install  dgl -f https://data.dgl.ai/wheels/cu117/repo.html\n",
        "%pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html\n",
        "\n",
        "import dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuHoN3sRGNip",
        "outputId": "e2548b8f-7e28-4fa9-9915-b11d2c03476b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.dgl.ai/wheels/cu117/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/cu117/dgl-1.0.1%2Bcu117-cp39-cp39-manylinux1_x86_64.whl (266.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.9/dist-packages (from dgl) (3.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (5.9.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.0.1+cu117\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Collecting dglgo\n",
            "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 KB\u001b[0m \u001b[31m410.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ruamel.yaml>=0.17.20\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.9/dist-packages (from dglgo) (6.0)\n",
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2022.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort>=5.10.1\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from dglgo) (1.10.6)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from dglgo) (1.2.2)\n",
            "Collecting ogb>=1.3.3\n",
            "  Downloading ogb-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpydoc>=1.1.0\n",
            "  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopep8>=1.6.0\n",
            "  Downloading autopep8-2.0.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dglgo) (0.7.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.9/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Collecting pycodestyle>=2.10.0\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx>=4.2\n",
            "  Downloading sphinx-6.1.3-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.9/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.13.1+cu116)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.4.4)\n",
            "Collecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (1.26.15)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.9/dist-packages (from ogb>=1.3.3->dglgo) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic>=1.9.0->dglgo) (4.5.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.4/519.4 KB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.2)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (63.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.27.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Collecting Pygments>=2.13\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.0)\n",
            "Collecting docutils<0.20,>=0.18\n",
            "  Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 KB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.8 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (6.0.0)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8->sphinx>=4.2->numpydoc>=1.1.0->dglgo) (3.15.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2022.12.7)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=9e03e0c546f0d228b8e28813bf361ab586d3de9dddcbd881424775261d62397a\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/bb/0d/2d02ec45f29c48d6192476bfb59c5a0e64b605e7212374dd15\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, Pygments, pycodestyle, isort, docutils, sphinx, ruamel.yaml, outdated, autopep8, ogb, numpydoc, dglgo\n",
            "  Attempting uninstall: Pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 3.5.4\n",
            "    Uninstalling Sphinx-3.5.4:\n",
            "      Successfully uninstalled Sphinx-3.5.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pygments-2.14.0 autopep8-2.0.2 dglgo-0.0.2 docutils-0.19 isort-5.12.0 littleutils-0.2.2 numpydoc-1.5.0 ogb-1.3.5 outdated-0.2.2 pycodestyle-2.10.0 rdkit-pypi-2022.9.5 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.7 sphinx-6.1.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DGL NN module consists of building blocks for GNN models. An NN module inherits from Pytorch’s NN Module, MXNet Gluon’s NN Block and TensorFlow’s Keras Layer, depending on the DNN framework backend in use. In a DGL NN module, the parameter registration in construction function and tensor operation in forward function are the same with the backend framework. In this way, DGL code can be seamlessly integrated into the backend framework code. The major difference lies in the message passing operations that are unique in DGL.\n",
        "\n",
        "This chapter takes SAGEConv with Pytorch backend as an example to introduce how to build a custom DGL NN Module."
      ],
      "metadata": {
        "id": "95yapkKFD7xq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DGL NN Module Construction Function\n",
        "\n",
        "The construction function performs the following steps:\n",
        "\n",
        "1. Set options.\n",
        "\n",
        "2. Register learnable parameters or submodules.\n",
        "\n",
        "3. Reset parameters."
      ],
      "metadata": {
        "id": "GttQSfugFFOd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nUe2a6LjD0tG"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from dgl.utils import expand_as_pair\n",
        "\n",
        "class SAGEConv(nn.Module):\n",
        "  def __init__(self,\n",
        "         in_feats,\n",
        "         out_feats,\n",
        "         aggregator_type,\n",
        "         bias=True,\n",
        "         norm=None,\n",
        "         activation=None):\n",
        "    super(SAGEConv,self).__init__()\n",
        "\n",
        "    self._in_src_feats,self._in_dst_feats=expand_as_pair(in_feats)\n",
        "    self._out_feats=out_feats\n",
        "    self._aggre_type=aggregator_type\n",
        "    self.norm=norm\n",
        "    self.activation=activation\n",
        "\n",
        "    # Part 2:aggregator type:mean,pool,lstm,gcn\n",
        "    if aggregator_type not in ['mean','pool','lstm','gcn']:\n",
        "      raise KeyError('Aggregator type {} not supported.'.format(aggregator_type))\n",
        "    if aggregator_type=='pool':\n",
        "      self.fc_loop=nn.Linear(self._in_src_feats,self._in_src_feats)\n",
        "    if aggregator_type=='lstm':\n",
        "      self.lstm=nn.LSTM(self._in_src_feats,self._in_src_feats,batch_first=True)\n",
        "    if aggregator_type in ['mean','pool','lstm']:\n",
        "      self.fc_self=nn.Linear(self._in_dst_feats, out_feats, bias=bias)\n",
        "    self.fc_neigh=nn.Linear(self._in_src_feats, out_feats, bias=bias)\n",
        "    self.reset_parameters()\n",
        "\n",
        "  # Part 3:\n",
        "  def reset_parameters(self):\n",
        "    \"\"\"Reinitialize learnable parameters.\"\"\"\n",
        "    gain=nn.init.calculate_gain('relu')\n",
        "    if self._aggre_type=='pool':\n",
        "      nn.init.xavier_uniform_(self.fc_pool.weight,gain=gain)\n",
        "    if self.aggre_type=='lstm':\n",
        "      self.lstm.reset_parameters()\n",
        "    if self._aggre_type!='gcn':\n",
        "      nn.init.xavier_uniform(self.fc_self.weightm,gain=gain)\n",
        "    nn.init.xavier_uniform_(self.fc_neigh.weight,gain=gain)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2:In construction function, one first needs to set the data dimensions. For general PyTorch module, the dimensions are usually input dimension, output dimension and hidden dimensions. For graph neural networks, the input dimension can be split into source node dimension and destination node dimension.(use expand_as_pair function)\n",
        "\n",
        "Besides data dimensions, a typical option for graph neural network is aggregation type (self._aggre_type). __Aggregation type determines how messages on different edges are aggregated for a certain destination node.__ Commonly used aggregation types include mean, sum, max, min. Some modules may apply more complicated aggregation like an lstm\n",
        "\n",
        "norm here is a callable function for feature normalization. In the SAGEConv paper, such normalization can be $L_2$ normalization:$h_v=\\frac{h_v}{||h_v||_2}$."
      ],
      "metadata": {
        "id": "nO8uLNdcH4I8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3:Register parameters and submodules. In SAGEConv, submodules vary according to the aggregation type. Those modules are pure PyTorch nn modules like nn.Linear, nn.LSTM, etc. At the end of construction function, weight initialization is applied by calling reset_parameters()."
      ],
      "metadata": {
        "id": "ON9T9kWJOGSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DGL NN Module Forward Function\n",
        "\n",
        "In NN module, forward() function does the actual message passing and computation. Compared with PyTorch’s NN module which usually takes tensors as the parameters, DGL NN module takes an additional parameter __dgl.DGLGraph__. The workload for forward() function can be split into three parts:\n",
        "\n",
        "*  Graph checking and graph type specification.\n",
        "\n",
        "*  Message passing.\n",
        "\n",
        "*  Feature update.\n",
        "\n",
        "The rest of the section takes a deep dive into the forward() function in SAGEConv example."
      ],
      "metadata": {
        "id": "DeIdnA38QZcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph checking and graph type specification\n",
        "\n",
        "forward() needs to handle many corner cases on the input that can lead to invalid values in computing and message passing. __One typical check in conv modules like GraphConv is to verify that the input graph has no 0-in-degree nodes.__ When a node has 0 in-degree, the mailbox will be empty and the reduce function will produce all-zero values. This may cause silent regression in model performance. __However, in SAGEConv module, the aggregated representation will be concatenated with the original node feature, the output of forward() will not be all-zero.__ No such check is needed in this case.\n",
        "\n",
        "DGL NN module should be reusable across different types of graph input including: homogeneous graph, heterogeneous graph, subgraph block \n",
        "\n",
        "The math formulas for SAGEConv are:\n",
        "\n",
        "$$h_{N(dst)}^{(l+1)}=aggregate(\\{h_{src}^l,∀src\\in N(dst)\\})$$\n",
        "\n",
        "$$h_{dst}^{(l+1)}=\\sigma(W\\cdot concat(h_{dst}^l,h_{N(dst)}^{l+1})+b)$$\n",
        "\n",
        "$$h_{dst}^{(l+1)}=norm(h_{dst}^{l+1})$$\n",
        "\n",
        "One needs to specify the source node feature feat_src and destination node feature feat_dst according to the graph type. expand_as_pair() is a function that specifies the graph type and expand feat into feat_src and feat_dst. The detail of this function is shown below.\n"
      ],
      "metadata": {
        "id": "MnKN_yocR1jE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self,graph,feat):\n",
        "  with graph.local_scope():\n",
        "    # Specify graph type then expand input feature according to graph type\n",
        "    feat_src,feat_dst=expand_as_pair(feat,graph)\n",
        "\n",
        "def expand_as_pair(input,g=None):\n",
        "  if isinstance(input_,tuple):\n",
        "    # Bipartite graph case\n",
        "    return input_\n",
        "  #这个部分不太懂\n",
        "  elif g is not None and g.is_block:\n",
        "    # Subgraph block case\n",
        "    if isinstance(input_,Mapping):\n",
        "      input_dst={\n",
        "          k:F.narrow_row(v,0,g.number_of_dst_nodes(k))\n",
        "          for k,v in input_.items()}\n",
        "    else:\n",
        "      input_dst=F.narrow_row(input_,0,g.number_of_dst_nodes())\n",
        "    return input_,input_dst\n",
        "  else:\n",
        "    # Homogeneous graph case\n",
        "    return input_,input_"
      ],
      "metadata": {
        "id": "atuy-hDDU34V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For homogeneous whole graph training, source nodes and destination nodes are the same. They are all the nodes in the graph.\n",
        "\n",
        "For heterogeneous case, the graph can be split into several bipartite graphs, one for each relation. The relations are represented as (src_type, edge_type, dst_dtype). When it identifies that the input feature feat is a tuple, it will treat the graph as bipartite. The first element in the tuple will be the source node feature and the second element will be the destination node feature.\n",
        "\n",
        "In mini-batch training, the computing is applied on a subgraph sampled based on a bunch of destination nodes. The subgraph is called as block in DGL. In the block creation phase, dst_nodes are in the front of the node list. One can find the feat_dst by the index [0:g.number_of_dst_nodes()].\n",
        "\n",
        "After determining feat_src and feat_dst, the computing for the above three graph types are the same."
      ],
      "metadata": {
        "id": "Yc9nmGgEZHo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Message passing and reducing\n",
        "\n",
        "The code actually does message passing and reducing computing. This part of code varies module by module. __Note that all the message passing in the above code are implemented using update_all() API and built-in message/reduce functions to fully utilize DGL’s performance optimization.__"
      ],
      "metadata": {
        "id": "nJN4cr6TZjPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl.function as fn\n",
        "import torch.nn.functional as F\n",
        "from dgl.utils import check_eq_shape\n",
        "\n",
        "if self.aggre_type=='mean':\n",
        "  graph.srcdata['h']=feat_src\n",
        "  graph.update_all(fn.copy_u('h','m'),fn.mean('m','neigh'))\n",
        "  h_neigh=graph.dstdata['neigh']\n",
        "elif self.aggre_type=='gcn':\n",
        "  check_eq_shape(feat)\n",
        "  graph.srcdata['h']=feat_src\n",
        "  graph.dstdata['h']=feat_dst\n",
        "  graph.update_all(fn.copy_u('h','m'),fn.sum('m','neigh'))\n",
        "  # divide in degrees\n",
        "  degs=graph.in_degrees().to(feat_dst)\n",
        "  h_neigh=(graph.dstdata['neigh']+graph.dstdata['h'])/(degs.unsqueeze(-1)+1)\n",
        "elif self.__aggre_type=='pool':\n",
        "   graph.srcdata['h']=F.relu(self,fc_pool(feat_src))\n",
        "   graph.update_all(fn.copy_u('h','m'),fn.max('m','neigh'))\n",
        "   h_neigh=graph.dstdata['neigh']\n",
        "else:\n",
        "  raise KeyError('Aggregator type {} not recognized.'.format(self._aggre_type))\n",
        "\n",
        "# GraphSAGE GCN does not require fc_self\n",
        "if self._aggre_type=='gcn':\n",
        "  rst=self.fc_neigh(h_neigh)\n",
        "else:\n",
        "  rst=self.fc_self(h_self)+self.fc_neigh(h_neigh)"
      ],
      "metadata": {
        "id": "GXlaqqUZZgEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update feature after reducing for output"
      ],
      "metadata": {
        "id": "_84R4KuMdt6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# activation\n",
        "if self.activation is not None:\n",
        "  rst=self.activation(rst)\n",
        "# normalization\n",
        "  rst=self.norm(rst)\n",
        "return rst"
      ],
      "metadata": {
        "id": "CSiiVXn2d9X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last part of forward() function is to update the feature after the reduce function. Common update operations are applying activation function and normalization according to the option set in the object construction phase."
      ],
      "metadata": {
        "id": "hUcXNKOreVeI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heterogeneous GraphConv Module\n",
        "\n",
        "HeteroGraphConv is a module-level encapsulation to run DGL NN module on heterogeneous graphs. The implementation logic is the same as message passing level API multi_update_all(), including:\n",
        "\n",
        "*  DGL NN module within each relation r\n",
        "\n",
        "*  Reduction that merges the results on the same node type from multiple relations\n",
        "\n",
        "This can be formulated as:\n",
        "\n",
        "$$h_{dst}^{(l+1)}=AGG_{r\\in R,r_{dst}=dst}(f_r(g_r,h_{r_{src}}^l,h_{r_{dst}}^l))$$\n",
        "\n",
        "where $f_r$ is the NN module for each relation r,AGG is the aggregation function"
      ],
      "metadata": {
        "id": "uu8Im5vh_LSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class HeteroGraphConv(nn.Module):\n",
        "  def __init__(self,mods,aggregate='sum'):\n",
        "    super(HeterGraphConv,self).__init__()\n",
        "    # dictionary mods:maps each relation to an nn module and\n",
        "    # sets the function that aggregates results on the same node\n",
        "    # type from multiple relations\n",
        "    self.mods=nn.ModuleDict(mods)\n",
        "    if isinstance(aggregate,str):\n",
        "      # An internal function to get common aggregation functions\n",
        "      self.agg_fn=get_aggregate_fn(aggregate)\n",
        "    else:\n",
        "      self.agg_fn=aggregate\n",
        "    \n",
        "  def forward(self,g,inputs,mod_args=None,mod_kwargs=None):\n",
        "    if mod_args is None:\n",
        "      mod_args={}\n",
        "    if mod_kwargs is None:\n",
        "      mod_kwargs={}\n",
        "    outputs={nty:[] for nty in g.dsttypes}"
      ],
      "metadata": {
        "id": "2T0CMcMnBNws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Besides input graph and input tensors, the forward() function takes two additional dictionary parameters mod_args and mod_kwargs. These two dictionaries have the same keys as self.mods. They are used as customized parameters when calling their corresponding NN modules in self.mods for different types of relations.\n",
        "\n",
        "An output dictionary is created to hold output tensor for each destination type nty . __Note that the value for each nty is a list, indicating a single node type may get multiple outputs if more than one relations have nty as the destination type.__ HeteroGraphConv will perform a further aggregation on the lists."
      ],
      "metadata": {
        "id": "7GC0mTNkDrnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if g.is_block:\n",
        "  src_inputs=inputs\n",
        "  dst_input={k:v[:g.number_of_dst_nodes(k)] for k,v in inputs.items()}\n",
        "else:\n",
        "  src_inputs=dst_inputs=inputs\n",
        "\n",
        "for stype,etype,dtype in g.canonical_etypes:\n",
        "  rel_graph=g[stype,etype,dtype]\n",
        "  if rel_graph.num_edges()==0:\n",
        "    continue\n",
        "  if stype not in src_inputs or dtype not in dst_inputs:\n",
        "    continue\n",
        "  dstdata=self.mods[etype](\n",
        "      rel_graph,\n",
        "      (src_inputs[stype],dst_inputs[dtype]),\n",
        "      *mod_args.get(etype,()),\n",
        "      **mod_kwargs.get(etype,{}))\n",
        "  outputs[dtype].append(dstdata)"
      ],
      "metadata": {
        "id": "KuKUrfpQECsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input g can be a heterogeneous graph or a subgraph block from a heterogeneous graph. As in ordinary NN module, the forward() function need to handle different input graph types separately.\n",
        "\n",
        "Each relation is represented as a canonical_etype, which is (stype, etype, dtype). Using canonical_etype as the key, one can extract out a bipartite graph rel_graph. For bipartite graph, the input feature will be organized as a tuple (src_inputs[stype], dst_inputs[dtype]). The NN module for each relation is called and the output is saved. To avoid unnecessary call, relations with no edges or no nodes with the src type will be skipped."
      ],
      "metadata": {
        "id": "a_IUEK16HFa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rsts={}\n",
        "for nty,alist in outputs.items():\n",
        "  if len(alist)!=0:\n",
        "    rsts[nty]=self.agg_fn(alist,nty)"
      ],
      "metadata": {
        "id": "Bwg1J-BlHJAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the results on the same destination node type from multiple relations are aggregated using self.agg_fn function. Examples can be found in the API Doc for HeteroGraphConv."
      ],
      "metadata": {
        "id": "LM40KTb3Hpcl"
      }
    }
  ]
}